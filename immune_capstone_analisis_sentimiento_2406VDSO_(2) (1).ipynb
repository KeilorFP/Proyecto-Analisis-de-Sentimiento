{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![ITI.jpg](https://drive.google.com/uc?export=view&id=1ois0vnRw0a0326tbE-ZA-8y3san-gf4d)"
      ],
      "metadata": {
        "id": "zpdMqs5r8jXH"
      },
      "id": "zpdMqs5r8jXH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capstone - Master en Data Science (2406VDSO)\n",
        "# IMMUNE Technology Insitute\n",
        "\n",
        "Autores:\n",
        "\n",
        "* Keilor Fallas\n",
        "* Lindsay López\n",
        "* Wendy Rodriguez\n",
        "* Allan Vargas"
      ],
      "metadata": {
        "id": "tnb9G-PuOOCS"
      },
      "id": "tnb9G-PuOOCS"
    },
    {
      "cell_type": "markdown",
      "id": "df617627",
      "metadata": {
        "id": "df617627"
      },
      "source": [
        "# **Sección 1**: Exploración y preparación de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3978a29",
      "metadata": {
        "id": "a3978a29"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f144d38",
      "metadata": {
        "collapsed": true,
        "id": "7f144d38"
      },
      "outputs": [],
      "source": [
        "!pip install pyjanitor # Solo si no está instalada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c909b3",
      "metadata": {
        "id": "06c909b3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import janitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e8c95a",
      "metadata": {
        "id": "53e8c95a"
      },
      "outputs": [],
      "source": [
        "# Conexión con Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b838ba",
      "metadata": {
        "id": "e7b838ba"
      },
      "source": [
        "## Limpieza de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f63896",
      "metadata": {
        "id": "57f63896"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Capstone IMMUNE /Datasets/DisneylandReviews/DisneylandReviews.csv', encoding='latin-1')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "654940ce",
      "metadata": {
        "id": "654940ce"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c98bb0e",
      "metadata": {
        "id": "0c98bb0e"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4acf8ab",
      "metadata": {
        "id": "b4acf8ab"
      },
      "outputs": [],
      "source": [
        "df.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9757b1d6",
      "metadata": {
        "id": "9757b1d6"
      },
      "outputs": [],
      "source": [
        "df_m=df.loc[df['Year_Month']=='missing']\n",
        "df_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62773e72",
      "metadata": {
        "id": "62773e72"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Capstone IMMUNE /Datasets/DisneylandReviews/DisneylandReviews.csv', encoding='latin-1', na_values=['missing'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7513c2bd",
      "metadata": {
        "id": "7513c2bd"
      },
      "outputs": [],
      "source": [
        "df=df.dropna().reset_index()\n",
        "print (\"\\nMissing values :  \", df.isnull().sum().values.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee8dbec",
      "metadata": {
        "id": "2ee8dbec"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb28034",
      "metadata": {
        "id": "1eb28034"
      },
      "outputs": [],
      "source": [
        "# Estandarizar nombre de variables\n",
        "\n",
        "df= df.clean_names()\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddfcea79",
      "metadata": {
        "id": "ddfcea79"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e3420e3",
      "metadata": {
        "id": "0e3420e3"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "661e5cf3",
      "metadata": {
        "id": "661e5cf3"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "367c728f",
      "metadata": {
        "id": "367c728f"
      },
      "outputs": [],
      "source": [
        "print(len(df['reviewer_location'].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08790e9b",
      "metadata": {
        "id": "08790e9b"
      },
      "outputs": [],
      "source": [
        "print(df['reviewer_location'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123ef7e6",
      "metadata": {
        "id": "123ef7e6"
      },
      "outputs": [],
      "source": [
        "print(df['branch'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47f1aeb0",
      "metadata": {
        "id": "47f1aeb0"
      },
      "outputs": [],
      "source": [
        "## Da formato a Year_Month de tal manera que el día tenga 2 dígitos\n",
        "\n",
        "df['year_month'] = df['year_month'].astype(str).apply(\n",
        "    lambda x: x if '-' not in x else x.split('-')[0] + '-' + x.split('-')[1].zfill(2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0203c572",
      "metadata": {
        "id": "0203c572"
      },
      "outputs": [],
      "source": [
        "df = df.drop('index', axis=1)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4d58725",
      "metadata": {
        "id": "d4d58725"
      },
      "outputs": [],
      "source": [
        "df['reviewer_location'] = df['reviewer_location'].str.strip()\n",
        "df['branch'] = df['branch'].str.strip()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c85c654b",
      "metadata": {
        "id": "c85c654b"
      },
      "outputs": [],
      "source": [
        "print(df['rating'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a8486d4",
      "metadata": {
        "id": "5a8486d4"
      },
      "source": [
        "# Análisis Exploratorio de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52cfa101",
      "metadata": {
        "id": "52cfa101"
      },
      "source": [
        "## Distribución Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e00a2c6",
      "metadata": {
        "id": "9e00a2c6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1a84c27",
      "metadata": {
        "id": "d1a84c27"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "ax = sns.histplot(data=df, x='rating', bins=range(1, 7), color='mediumslateblue', edgecolor='black', discrete=True)\n",
        "\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(p.get_x() + p.get_width()/2, height + 1, int(height), ha=\"center\")\n",
        "\n",
        "plt.title('Distribución de Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a32be50",
      "metadata": {
        "id": "0a32be50"
      },
      "source": [
        "## Distribución por Parque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72e1c933",
      "metadata": {
        "id": "72e1c933"
      },
      "outputs": [],
      "source": [
        "branch_counts = df['branch'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "branch_counts.plot.pie(autopct='%1.1f%%', colors=sns.color_palette('pastel', len(branch_counts)), startangle=90)\n",
        "plt.title('Distribución de reseñas por Parque')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21d4b072",
      "metadata": {
        "id": "21d4b072"
      },
      "source": [
        "## Cantidad de países"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54b40f39",
      "metadata": {
        "id": "54b40f39"
      },
      "outputs": [],
      "source": [
        "print(\"Número de países únicos:\", df['reviewer_location'].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57085c14",
      "metadata": {
        "id": "57085c14"
      },
      "source": [
        "## Países con más reseñas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d4e298",
      "metadata": {
        "id": "92d4e298"
      },
      "outputs": [],
      "source": [
        "top_paises = df['reviewer_location'].value_counts().head(10)\n",
        "sns.barplot(x=top_paises.values, y=top_paises.index, palette='coolwarm')\n",
        "plt.title('Top 10 países con mas reseñas')\n",
        "plt.xlabel('Cantidad de reseñas')\n",
        "plt.ylabel('País')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dedd3eb0",
      "metadata": {
        "id": "dedd3eb0"
      },
      "source": [
        "## Reseñas por año"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f47549d",
      "metadata": {
        "id": "1f47549d"
      },
      "outputs": [],
      "source": [
        "df['year_month'] = pd.to_datetime(df['year_month'], format='%Y-%m', errors='ignore')\n",
        "\n",
        "reviews_by_month = df.groupby('year_month').size()\n",
        "reviews_by_month.plot()\n",
        "plt.title('Reseñas a lo largo del tiempo')\n",
        "plt.xlabel('Fecha')\n",
        "plt.ylabel('Cantidad de reseñas')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db7a0532",
      "metadata": {
        "id": "db7a0532"
      },
      "source": [
        "## Distribución de sentimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb04991",
      "metadata": {
        "id": "4eb04991"
      },
      "outputs": [],
      "source": [
        "df['target'] = df['rating'].apply(lambda x: 1 if x >= 4 else 0)\n",
        "print(df['target'].value_counts())\n",
        "sns.countplot(x='target', data=df, palette='muted')\n",
        "plt.title('Distribución de Sentimiento')\n",
        "plt.xlabel('Sentimiento')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.xticks([0,1], ['Negativa', 'Positiva'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección 2: Modelos de Machine Learning"
      ],
      "metadata": {
        "id": "snm4dxp4Qdn6"
      },
      "id": "snm4dxp4Qdn6"
    },
    {
      "cell_type": "markdown",
      "id": "c534e5a7",
      "metadata": {
        "id": "c534e5a7"
      },
      "source": [
        "# Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Liberias para modelos"
      ],
      "metadata": {
        "id": "iqGjIenKPUeK"
      },
      "id": "iqGjIenKPUeK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar df nuevamente para utilizar dataset completo\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Capstone IMMUNE /Datasets/DisneylandReviews/DisneylandReviews.csv', encoding='latin-1').clean_names()\n",
        "df"
      ],
      "metadata": {
        "id": "GFc_mNqi56ie"
      },
      "id": "GFc_mNqi56ie",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
        "                            recall_score, f1_score, confusion_matrix, roc_curve,\n",
        "                            auc, classification_report, precision_recall_curve,\n",
        "                            average_precision_score)\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "import joblib"
      ],
      "metadata": {
        "id": "P-pCXzBGPLgy"
      },
      "id": "P-pCXzBGPLgy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de reseñas para modelos"
      ],
      "metadata": {
        "id": "mzQw-p0qQ8oy"
      },
      "id": "mzQw-p0qQ8oy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías de procesamiento de texto\n",
        "import nltk\n",
        "from nltk.corpus import stopwords # Para manejar las stopwords ('palabras vacías')\n",
        "from nltk.tokenize import word_tokenize # Divide el texto en tokens ('palabras individuales')\n",
        "from nltk.stem import WordNetLemmatizer # Reduce las palabras a su forma base\n",
        "nltk.download('all',quiet=True) # Expresiones regulares\n",
        "import re\n"
      ],
      "metadata": {
        "id": "m-I3C9eaQ4-b"
      },
      "id": "m-I3C9eaQ4-b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Creación de función para limpieza de texto\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)             # URLs\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)                    # menciones/hashtags\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)                  # puntuación y números\n",
        "    text = text.lower()                                      # minúsculas\n",
        "    tokens = nltk.word_tokenize(text)                        # tokenización\n",
        "    tokens = [tok for tok in tokens if tok not in stop_words]  # stopwords\n",
        "    tokens = [lemmatizer.lemmatize(tok) for tok in tokens]     # lematización\n",
        "    return ' '.join(tokens)\n"
      ],
      "metadata": {
        "id": "4qbslBGNTXpR"
      },
      "id": "4qbslBGNTXpR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar fórmula al texto de las reseñas\n",
        "\n",
        "df['clean_review_text'] = df['review_text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "n2bW_IL9Teoy"
      },
      "id": "n2bW_IL9Teoy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra de reviews limpias\n",
        "\n",
        "print(df[['review_text','clean_review_text']].head())"
      ],
      "metadata": {
        "id": "pgv3SNSVTfbZ"
      },
      "id": "pgv3SNSVTfbZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de variable 'target'"
      ],
      "metadata": {
        "id": "UXn_Uv2oXtGq"
      },
      "id": "UXn_Uv2oXtGq"
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'] = df['rating'].apply(lambda x: 1 if x >= 4 else 0) # Definición de variable target"
      ],
      "metadata": {
        "id": "Amv3peFZXyoZ"
      },
      "id": "Amv3peFZXyoZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['target'].value_counts())"
      ],
      "metadata": {
        "id": "LeRBybHbX0gr"
      },
      "id": "LeRBybHbX0gr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar df limpio\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/Capstone IMMUNE /Datasets/DisneylandReviews/DisneylandReviews_clean.csv', index=False)"
      ],
      "metadata": {
        "id": "u3ZsLs2GcVTY"
      },
      "id": "u3ZsLs2GcVTY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar df limpio\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Capstone IMMUNE /Datasets/DisneylandReviews/DisneylandReviews_clean.csv')\n"
      ],
      "metadata": {
        "id": "7Vja1atacXP_"
      },
      "id": "7Vja1atacXP_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train - Test"
      ],
      "metadata": {
        "id": "ZcZ-0A2SDhui"
      },
      "id": "ZcZ-0A2SDhui"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test\n",
        "\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.2,\n",
        "                                     stratify=df[\"target\"],\n",
        "                                     random_state=42)\n",
        "\n",
        "\n",
        "print('Clases en datos de entrenamiento')\n",
        "print(df_train['target'].value_counts())\n",
        "\n",
        "\n",
        "print('Clases en datos de prueba')\n",
        "print(df_test['target'].value_counts())\n",
        "\n",
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']"
      ],
      "metadata": {
        "id": "F8mEiwyaDgIJ"
      },
      "id": "F8mEiwyaDgIJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar composición de los DF\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "id": "ErpjcjSoctGC"
      },
      "id": "ErpjcjSoctGC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Balanceo de clases\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df_train_positive= df_train[df_train['target'] == 1]\n",
        "df_train_negative = df_train[df_train['target'] == 0]\n",
        "\n",
        "df_train_positive_downsampled =  resample(df_train_positive,\n",
        "                                    replace=False,\n",
        "                                    n_samples=len(df_train_negative)\n",
        "                                    )\n",
        "df_train_bal = pd.concat([df_train_positive_downsampled,df_train_negative],axis=0)\n",
        "\n",
        "# Verificar balanceo de clases\n",
        "\n",
        "print('Clases en datos de entrenamiento')\n",
        "print(df_train_bal['target'].value_counts())\n",
        "\n",
        "\n",
        "print('Clases en datos de prueba')\n",
        "print(df_test['target'].value_counts())'''"
      ],
      "metadata": {
        "id": "xGtPEtDlXc_C"
      },
      "id": "xGtPEtDlXc_C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir class_weight para tomar en cuenta las diferencias de clases en los modelos\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "print(class_weights_dict)"
      ],
      "metadata": {
        "id": "bGduxHmpht-5"
      },
      "id": "bGduxHmpht-5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3c2e82e9",
      "metadata": {
        "id": "3c2e82e9"
      },
      "source": [
        "## Regresión Logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4758788",
      "metadata": {
        "id": "b4758788"
      },
      "outputs": [],
      "source": [
        "# Creación de variables de test y train\n",
        "\n",
        "features = ['branch', 'reviewer_location', 'clean_review_text']\n",
        "X_train = df_train[features]\n",
        "y_train = df_train['target']\n",
        "X_test = df_test[features]\n",
        "y_test = df_test['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d94ad7",
      "metadata": {
        "id": "73d94ad7"
      },
      "outputs": [],
      "source": [
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('text', TfidfVectorizer(max_features=5000, stop_words='english'), 'clean_review_text'),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['branch', 'reviewer_location'])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df43e0f",
      "metadata": {
        "id": "5df43e0f"
      },
      "outputs": [],
      "source": [
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(C=0.1, penalty='l2', solver='liblinear', class_weight='balanced', max_iter=1000))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7176202",
      "metadata": {
        "id": "f7176202"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10],\n",
        "    'classifier__penalty': ['l1', 'l2'],\n",
        "    'classifier__solver': ['liblinear']\n",
        "}\n",
        "\n",
        "logreg_grid = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
        "logreg_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", logreg_grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd91a8c",
      "metadata": {
        "id": "1dd91a8c"
      },
      "outputs": [],
      "source": [
        "# Predecir las probabilidades para el set de prueba\n",
        "\n",
        "y_probs = logreg_grid.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Predecir la clases para el set de prueba\n",
        "\n",
        "y_pred = logreg_grid.predict(X_test)\n",
        "\n",
        "# Matriz de confusión\n",
        "\n",
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe36f892",
      "metadata": {
        "id": "fe36f892"
      },
      "outputs": [],
      "source": [
        "report_rl = classification_report(y_test, y_pred, target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print(\"\\nReporte de clasificación: Regresión Logística\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negativa', 'Positiva']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el AUC - ROC score\n",
        "roc_auc_rl = roc_auc_score(y_test, y_probs)"
      ],
      "metadata": {
        "id": "tHU6fc4nDAVq"
      },
      "id": "tHU6fc4nDAVq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar curva ROC\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "roc_auc_rl = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_rl:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Tasa de Falsos Positivos')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "plt.title('ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NaVGQ53zEmMA"
      },
      "id": "NaVGQ53zEmMA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular precision y recall para varios umbrales\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "\n",
        "# Calcular el Average Precision Score\n",
        "avg_precision = average_precision_score(y_test, y_probs)\n",
        "\n",
        "# Graficar la curva Precision-Recall\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xa7AB4ZrD69j"
      },
      "id": "Xa7AB4ZrD69j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo es bueno detectando positivos, con un 85% de recall para la clase 1. Sin embargo, su desempeño en detectar negativos es más limitado, con un 82% de recall para la clase 0.\n",
        "En la matriz de confusión se observa que 1324 ejemplos fueron correctamente clasificados como negativos, y 286 fueron erróneamente clasificados como positivos.\n",
        "La precisión general del modelo (accuracy) fue del 84%."
      ],
      "metadata": {
        "id": "8jwlswpzI36L"
      },
      "id": "8jwlswpzI36L"
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo\n",
        "\n",
        "joblib.dump(logreg_grid, '/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/logreg_grid.pkl')"
      ],
      "metadata": {
        "id": "YDgbv_u_IPaO"
      },
      "id": "YDgbv_u_IPaO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f5e66143",
      "metadata": {
        "id": "f5e66143"
      },
      "source": [
        "## Support vector machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd507339",
      "metadata": {
        "id": "bd507339"
      },
      "outputs": [],
      "source": [
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99353560",
      "metadata": {
        "id": "99353560"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58f114ce",
      "metadata": {
        "id": "58f114ce"
      },
      "outputs": [],
      "source": [
        "svm = SVC(kernel='linear',probability=True, random_state=42,class_weight='balanced')\n",
        "svm.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a777c383",
      "metadata": {
        "id": "a777c383"
      },
      "outputs": [],
      "source": [
        "# Predecir las probabilidades para el set de prueba\n",
        "\n",
        "y_probs = svm.predict_proba(X_test_tfidf)[:,1]\n",
        "\n",
        "# Predecir la clases para el set de prueba\n",
        "\n",
        "y_pred = svm.predict(X_test_tfidf)\n",
        "\n",
        "# Matriz de confusión\n",
        "\n",
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Classification report\n",
        "\n",
        "report_svm = classification_report(y_test, y_pred, target_names=['Negativa', 'Positiva'], output_dict=True)\n",
        "print(print(\"\\nReporte de clasificación: SVM\"))\n",
        "print(classification_report(y_test, y_pred, target_names=['Negativa', 'Positiva']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "roc_auc_svm = auc(fpr, tpr)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"AUC: {roc_auc_svm:.2f}\")\n",
        "\n",
        "# Graficar la curva ROC\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_svm:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # línea base\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tkTI5Np_gKhZ"
      },
      "id": "tkTI5Np_gKhZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular precision y recall para la curva\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "\n",
        "# Calcular el average precision score\n",
        "avg_precision = average_precision_score(y_test, y_probs)\n",
        "\n",
        "# Graficar la curva Precision-Recall\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall (SVM)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y46gLNW8FrFT"
      },
      "id": "y46gLNW8FrFT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo SVM tiene un buen desempeño general, logrando un 85% de recall para la clase Positiva, pero solo un 81% de recall para la clase Negativa.\n",
        "En la matriz de confusión se observa que el modelo identifica correctamente la mayoría de los casos positivos, aunque le cuesta más clasificar adecuadamente los negativos.\n",
        "La precisión general del modelo (accuracy) fue del 84%."
      ],
      "metadata": {
        "id": "YXSDPSotRh35"
      },
      "id": "YXSDPSotRh35"
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo SVM y el vectorizador\n",
        "\n",
        "joblib.dump(svm, '/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/svm_model.pkl')\n",
        "joblib.dump(vectorizer, '/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/tfidf_vectorizer.pkl')"
      ],
      "metadata": {
        "id": "_s_J3R-kIkEG"
      },
      "id": "_s_J3R-kIkEG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7d14f828",
      "metadata": {
        "id": "7d14f828"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d502c888",
      "metadata": {
        "id": "d502c888"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']"
      ],
      "metadata": {
        "id": "qEdQRXAJc7jD"
      },
      "id": "qEdQRXAJc7jD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166c4009",
      "metadata": {
        "id": "166c4009"
      },
      "outputs": [],
      "source": [
        "# Normalizar los pesos de las clases\n",
        "\n",
        "class_weights_norm = class_weights / class_weights.sum()\n",
        "\n",
        "# Modelo\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_tfidf, y_train)\n",
        "y_pred_nb = nb.predict(X_test_tfidf)\n",
        "y_probs = nb.predict_proba(X_test_tfidf)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa971e39",
      "metadata": {
        "id": "aa971e39"
      },
      "outputs": [],
      "source": [
        "report_nb = classification_report(y_test, y_pred_nb, target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print(\"\\n Naive Bayes \")\n",
        "print(classification_report(y_test, y_pred_nb, target_names=['Negativa', 'Positiva']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38674300",
      "metadata": {
        "id": "38674300"
      },
      "outputs": [],
      "source": [
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "roc_auc_nb = auc(fpr, tpr)\n",
        "print(f\"AUC: {roc_auc_nb:.2f}\")\n",
        "\n",
        "# Graficar curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_nb:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel(\"Tasa de falsos positivos\")\n",
        "plt.ylabel(\"Tasa de verdaderos positivos\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W2PJ10dVg2mY"
      },
      "id": "W2PJ10dVg2mY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular precisión y recall\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "avg_precision = average_precision_score(y_test, y_probs)\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall (Naive Bayes)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ThWv_pljGC3S"
      },
      "id": "ThWv_pljGC3S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo bueno detectando positivas 86%, pero de los realmente negativos detecto un 32%\n",
        "En la matriz de confusion se observa que 518 fueron correctamente clasificadas como negativas y 1092 fueron erroneamente clasificadas como positivas."
      ],
      "metadata": {
        "id": "Xlh9XeQjUQVB"
      },
      "id": "Xlh9XeQjUQVB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo Naive Bayes\n",
        "joblib.dump(nb, '/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/nb_model.pkl')"
      ],
      "metadata": {
        "id": "3tW0v9LBUNMB"
      },
      "id": "3tW0v9LBUNMB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5206c029",
      "metadata": {
        "id": "5206c029"
      },
      "source": [
        "## Árbol de Decisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92880f79",
      "metadata": {
        "id": "92880f79"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']"
      ],
      "metadata": {
        "id": "-Mi9-Crvc9IC"
      },
      "id": "-Mi9-Crvc9IC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee7a3e4",
      "metadata": {
        "id": "8ee7a3e4"
      },
      "outputs": [],
      "source": [
        "tree = DecisionTreeClassifier(max_depth=15, random_state=42,class_weight='balanced')\n",
        "tree.fit(X_train_tfidf, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tree = tree.predict(X_test_tfidf)\n",
        "y_probs = tree.predict_proba(X_test_tfidf)"
      ],
      "metadata": {
        "id": "2vOg2fmXHR0m"
      },
      "id": "2vOg2fmXHR0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaa300b3",
      "metadata": {
        "id": "aaa300b3"
      },
      "outputs": [],
      "source": [
        "report_dt = classification_report(y_test, y_pred_tree, target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print(\"\\n Reporte de Clasificación: Árbol de Decisión \")\n",
        "print(pd.DataFrame.from_dict(report_dt).round(2).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca731df",
      "metadata": {
        "id": "2ca731df"
      },
      "outputs": [],
      "source": [
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred_tree))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, 1])\n",
        "roc_auc_dt = auc(fpr, tpr)\n",
        "print(f\"AUC: {roc_auc_dt:.2f}\")\n",
        "\n",
        "# Graficar curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_dt:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel(\"Tasa de falsos positivos\")\n",
        "plt.ylabel(\"Tasa de verdaderos positivos\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_GLtJH4cluN0"
      },
      "id": "_GLtJH4cluN0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener probabilidades de la clase positiva\n",
        "y_probs_tree = y_probs[:, 1]\n",
        "\n",
        "# Calcular precision y recall\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs_tree)\n",
        "avg_precision = average_precision_score(y_test, y_probs_tree)\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall (Árbol de Decisión)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qJiONCJqHPK-"
      },
      "id": "qJiONCJqHPK-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo detecta el 89% de las reseñas positivas pero solo detecta el 43% de las reseñas negativas"
      ],
      "metadata": {
        "id": "4E8NPP9aVZ6s"
      },
      "id": "4E8NPP9aVZ6s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e8d4357",
      "metadata": {
        "id": "1e8d4357"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd2e6cf",
      "metadata": {
        "id": "8fd2e6cf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 10))  # Ajusta el tamaño si quieres\n",
        "plot_tree(tree,\n",
        "          filled=True,\n",
        "          feature_names=vectorizer.get_feature_names_out(),\n",
        "          class_names=['Negativa', 'Positiva'],\n",
        "          max_depth=2, # Solo mostrar 2 niveles para que sea más claro\n",
        "          fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c161477",
      "metadata": {
        "id": "1c161477"
      },
      "source": [
        "Con el arbol de decision se observa que hay mas reseñas positivas por lo que genera una tendencia en los modelos a predecir mayormente reseñas positivas para tener mas aciertos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo de Árbol de Decisión\n",
        "joblib.dump(tree, '/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/tree_model.pkl')"
      ],
      "metadata": {
        "id": "cNvJkHWTJU5O"
      },
      "id": "cNvJkHWTJU5O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "OacT1fHqnM7o"
      },
      "id": "OacT1fHqnM7o"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "EHAguKhPnazv"
      },
      "id": "EHAguKhPnazv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test Split\n",
        "\n",
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']\n",
        "\n",
        "# ratio = cantidad de negativos / positivos\n",
        "ratio = sum(y_train == 0) / sum(y_train == 1)\n",
        "\n",
        "\n",
        "# Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),  # Convierte texto en vectores\n",
        "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42,scale_pos_weight=ratio))\n",
        "])\n",
        "\n",
        "# Espacio de busqueda\n",
        "\n",
        "param_dist = {\n",
        "    'tfidf__max_df': [0.8, 0.9, 1.0],\n",
        "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
        "    'xgb__n_estimators': [100, 200, 300],\n",
        "    'xgb__max_depth': [3, 4, 5, 6],\n",
        "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
        "    'xgb__subsample': [0.8, 1.0],\n",
        "    'xgb__colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "# Hacer el fit del modelo\n",
        "\n",
        "search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Y5wteAhBnbv_"
      },
      "id": "Y5wteAhBnbv_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "y_pred = search.predict(X_test)\n",
        "report_xgb = classification_report(y_test, y_pred,target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print(\"Mejores parámetros encontrados:\", search.best_params_)\n",
        "print(\"\\n Reporte de Clasificación: XGBoost\")\n",
        "print(pd.DataFrame.from_dict(report_xgb).round(2).T)"
      ],
      "metadata": {
        "id": "j_Px28Xfmdqa"
      },
      "id": "j_Px28Xfmdqa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las probabilidades con el mejor modelo\n",
        "best_model = search.best_estimator_\n",
        "y_probs = best_model.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva\n",
        "\n",
        "# Calcular curva ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "roc_auc_xgb = auc(fpr, tpr)\n",
        "print(f\"AUC: {roc_auc_xgb:.2f}\")\n",
        "\n",
        "# Graficar curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_xgb:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aq90ta7ChWJC"
      },
      "id": "aq90ta7ChWJC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular precisión y recall\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "avg_precision = average_precision_score(y_test, y_probs)\n",
        "print(f\"Average Precision (AP): {avg_precision:.2f}\")\n",
        "\n",
        "# Graficar curva Precision-Recall\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}', color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall del Mejor Modelo')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a3d1qCiO1yAP"
      },
      "id": "a3d1qCiO1yAP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo encontrado por RandomizedSearchCV\n",
        "best_model = search.best_estimator_\n",
        "\n",
        "# Guardar el modelo en Google Drive\n",
        "joblib.dump(best_model, '/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/xgb_best_model.pkl')"
      ],
      "metadata": {
        "id": "rNh1IF6LJ1oM"
      },
      "id": "rNh1IF6LJ1oM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVCLinear"
      ],
      "metadata": {
        "id": "J2HiwFiYRwCr"
      },
      "id": "J2HiwFiYRwCr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1aCm7f8IM-N"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy.sparse import hstack\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.decomposition import TruncatedSVD\n"
      ],
      "id": "v1aCm7f8IM-N"
    },
    {
      "cell_type": "code",
      "source": [
        "# División train/test\n",
        "\n",
        "X, X_test, y, y_test = train_test_split(\n",
        "    df['clean_review_text'], df['target'], test_size=0.2,\n",
        "    random_state=42, stratify=df['target']\n",
        ")"
      ],
      "metadata": {
        "id": "CWcvaZPuSDQ6"
      },
      "id": "CWcvaZPuSDQ6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['target'].value_counts())"
      ],
      "metadata": {
        "id": "vmX3wi0q4MhF"
      },
      "id": "vmX3wi0q4MhF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracción de features\n",
        "tfidf = TfidfVectorizer(max_features=15000, ngram_range=(3,5), analyzer='char')\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "embed = SentenceTransformer('all-mpnet-base-v2')\n",
        "emb = embed.encode(X.tolist(), batch_size=128, show_progress_bar=True)\n",
        "emb_test = embed.encode(X_test.tolist(), batch_size=128, show_progress_bar=True)\n",
        "X_feat = hstack([X_tfidf, emb])\n",
        "X_test_feat = hstack([X_test_tfidf, emb_test])"
      ],
      "metadata": {
        "id": "AteqESJjSHCz"
      },
      "id": "AteqESJjSHCz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducir solo la parte TF-IDF\n",
        "svd = TruncatedSVD(n_components=300, random_state=42)\n",
        "X_tfidf_reduced = svd.fit_transform(X_tfidf)\n",
        "X_test_tfidf_reduced = svd.transform(X_test_tfidf)\n",
        "\n",
        "# Concatenar con los embeddings densos\n",
        "X_feat = np.hstack([X_tfidf_reduced, emb])\n",
        "X_test_feat = np.hstack([X_test_tfidf_reduced, emb_test])\n"
      ],
      "metadata": {
        "id": "6X_FQkFcShV9"
      },
      "id": "6X_FQkFcShV9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# División para calibración y umbral\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_feat, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "RAN2VW60Sle4"
      },
      "id": "RAN2VW60Sle4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Búsqueda de hiperparámetros en train\n",
        "\n",
        "base_svc = LinearSVC(class_weight='balanced', max_iter=10000)\n",
        "search = RandomizedSearchCV(\n",
        "    LinearSVC(class_weight='balanced', max_iter=15000),\n",
        "    {'C': np.logspace(-4,1,20)},\n",
        "    n_iter=15, scoring='f1', cv=StratifiedKFold(5),\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "search.fit(X_train, y_train)\n",
        "best_svc = search.best_estimator_\n",
        "\n",
        "print(f\"Mejor SVC C={search.best_params_['C']}, F1 train CV={search.best_score_:.3f}\")"
      ],
      "metadata": {
        "id": "pqwFD5PYSmqi"
      },
      "id": "pqwFD5PYSmqi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibración y umbral\n",
        "calibrated = CalibratedClassifierCV(best_svc, method='sigmoid', cv='prefit')\n",
        "calibrated.fit(X_train, y_train)\n",
        "\n",
        "y_val_probs = calibrated.predict_proba(X_val)[:,1]\n",
        "dp_val, dr_val, dt_val = precision_recall_curve(y_val, y_val_probs)\n",
        "f1_scores_val = 2 * dp_val * dr_val / (dp_val + dr_val + 1e-6)\n",
        "best_idx_val = np.nanargmax(f1_scores_val)\n",
        "best_thr = dt_val[best_idx_val]\n"
      ],
      "metadata": {
        "id": "sGSXcaXmSoaO"
      },
      "id": "sGSXcaXmSoaO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación final en test con umbral fijado\n",
        "y_test_probs = calibrated.predict_proba(X_test_feat)[:,1]\n",
        "y_pred = (y_test_probs >= best_thr).astype(int)\n",
        "report_svcl = classification_report(y_test, y_pred, target_names=['Negativa','Positiva'],\n",
        "                            output_dict=True)\n",
        "\n",
        "print(\"\\n Reporte de Clasificación: SVC\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negativa','Positiva']))\n"
      ],
      "metadata": {
        "id": "sdfYuRj8St1A"
      },
      "id": "sdfYuRj8St1A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_probs)\n",
        "roc_auc_svcl = auc(fpr, tpr)\n",
        "print(f\"AUC: {roc_auc_svcl:.2f}\")\n",
        "\n",
        "# Graficar curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_svcl:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel(\"Tasa de falsos positivos\")\n",
        "plt.ylabel(\"Tasa de verdaderos positivos\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DXlo_eGNTOtE"
      },
      "id": "DXlo_eGNTOtE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular precision y recall\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_test_probs)\n",
        "avg_precision = average_precision_score(y_test, y_test_probs)\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall (SVCLinear)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "avvq6lCOTZlD"
      },
      "id": "avvq6lCOTZlD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "22c8c6c7",
      "metadata": {
        "id": "22c8c6c7"
      },
      "source": [
        "# **Sección 3**: Modelos de DeepLearning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2becbf69",
      "metadata": {
        "id": "2becbf69"
      },
      "source": [
        "# Modelos DeepLearning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d897e6",
      "metadata": {
        "id": "92d897e6"
      },
      "source": [
        "## Análisis de sentimiento con NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af361e69",
      "metadata": {
        "id": "af361e69"
      },
      "source": [
        "### Importar paquetes necesarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a709a20",
      "metadata": {
        "id": "1a709a20"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords # Para manejar las stopwords ('palabras vacías')\n",
        "from nltk.tokenize import word_tokenize # Divide el texto en tokens ('palabras individuales')\n",
        "from nltk.stem import WordNetLemmatizer # Reduce las palabras a su forma base\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer # Analizador de sentimientos\n",
        "\n",
        "nltk.download('all',quiet=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b5b811",
      "metadata": {
        "id": "40b5b811"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4dba93",
      "metadata": {
        "id": "cd4dba93"
      },
      "outputs": [],
      "source": [
        "# Instanciar SentimentIntensityAnalizer\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Crear una fucnión para definir el mejor umbral para la clasificación con SIA\n",
        "\n",
        "def find_best_threshold(df, true_label_col='true_label', text_col='clean_review_text'):\n",
        "    thresholds = np.arange(-1.0, 1.01, 0.01)\n",
        "    best_threshold = 0.0\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Precalcular los compound scores\n",
        "    df['compound'] = df[text_col].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        preds = df['compound'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "        f1 = f1_score(df[true_label_col], preds)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "\n",
        "    return best_threshold, best_f1\n",
        "\n",
        "# Definir el mejor umbral\n",
        "\n",
        "best_thresh, best_f1 = find_best_threshold(df,'target')\n",
        "print(f\"Best threshold: {best_thresh}, F1-score: {best_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una función para clasificar el sentimiento de las reseñas\n",
        "\n",
        "def classify_sentiment(text,threshold=0):\n",
        "  # Remover stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = word_tokenize(text)\n",
        "  filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "  text = ' '.join(filtered_words)\n",
        "  sentiment_score = sia.polarity_scores(text) # Genera scores en relación con si el texto es positivo, negativo o neutro\n",
        "  compound_score = sentiment_score['compound'] # Resumen del sentimiento en general\n",
        "  if compound_score >= threshold: # Clasifica según sea el sentimiento general\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# Aplicar función a los datos\n",
        "\n",
        "df['sentiment_score'] = df['clean_review_text'].\\\n",
        "                        apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
        "\n",
        "df['sentiment'] = df['clean_review_text'].\\\n",
        "                  apply(lambda text: classify_sentiment(text, threshold=best_thresh))"
      ],
      "metadata": {
        "id": "wocTWc7n2ufc"
      },
      "id": "wocTWc7n2ufc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12ca9a7",
      "metadata": {
        "id": "f12ca9a7"
      },
      "outputs": [],
      "source": [
        "print(df[['clean_review_text', 'sentiment_score', 'sentiment']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a77e232",
      "metadata": {
        "id": "2a77e232"
      },
      "source": [
        "### Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b482548a",
      "metadata": {
        "id": "b482548a"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusion\n",
        "\n",
        "print('Matriz de confusión: NLTK')\n",
        "\n",
        "cm = confusion_matrix(df['target'],\n",
        "                      df['sentiment'])\n",
        "\n",
        "print(\"Matriz de confusión:\")\n",
        "print(cm)\n",
        "\n",
        "# Accuracy score entre 'rating_class' y 'sentiment\n",
        "\n",
        "print('Accuracy Score: NLTK')\n",
        "\n",
        "accuracy = accuracy_score(df['target'],\n",
        "                          df['sentiment'])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Accuracy score por variable\n",
        "\n",
        "for sentiment in df['sentiment'].unique():\n",
        "    validation_df = df[df['sentiment'] == sentiment]\n",
        "    accuracy = accuracy_score(df['sentiment'],\n",
        "                              df['target'])\n",
        "    print(f\"Accuracy for {sentiment}: {accuracy:.2f}\")\n",
        "\n",
        "# Classification report\n",
        "\n",
        "report_nltk = classification_report(df['target'],df['sentiment'],target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print(\"\\n Reporte de Clasificación: NLTK\")\n",
        "print(pd.DataFrame.from_dict(report_nltk).round(2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Etiquetas reales\n",
        "y_true = df['target']\n",
        "\n",
        "# Puntajes continuos\n",
        "y_scores = df['sentiment_score']\n",
        "\n",
        "# Calcular puntos ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "roc_auc_nltk = auc(fpr, tpr)\n",
        "\n",
        "# Graficar curva ROC\n",
        "print(f\"AUC: {roc_auc_nltk:.2f}\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc_nltk:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC - NLTK')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YcGUGGf8v-LI"
      },
      "id": "YcGUGGf8v-LI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular precisión, recall y Average Precision\n",
        "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
        "avg_precision = average_precision_score(y_true, y_scores)\n",
        "\n",
        "# Graficar curva Precision-Recall\n",
        "print(f\"Average Precision (AP): {avg_precision:.2f}\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}', color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall - NLTK')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v2H5mkr2qmy"
      },
      "id": "7v2H5mkr2qmy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "424bf3ce",
      "metadata": {
        "id": "424bf3ce"
      },
      "source": [
        "## Análisis de sentimiento con RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5831883f",
      "metadata": {
        "id": "5831883f"
      },
      "source": [
        "### Importar paquetes necesarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18d1fd63",
      "metadata": {
        "id": "18d1fd63"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # Tensor flow\n",
        "from tensorflow.keras.models import Sequential, Model #  Modelo secuencial\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, Dropout # Layers requeridas\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Creación de tokens\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Normalización de texto\n",
        "from tensorflow.keras.callbacks import EarlyStopping # EarlyStopping para evitar el overfitting\n",
        "from sklearn.model_selection import train_test_split # Train/Test split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb18df06",
      "metadata": {
        "id": "bb18df06"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b09189e1",
      "metadata": {
        "id": "b09189e1"
      },
      "outputs": [],
      "source": [
        "# Train/Test Split\n",
        "\n",
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']\n",
        "\n",
        "\n",
        "# Crear tokens y ajustar las secuencias\n",
        "max_vocab = 10000 # Tamaño máximo de palabras a tomar en cuenta del texto\n",
        "\n",
        "lengths = []\n",
        "for index, text in df['clean_review_text'].items():\n",
        "    lengths.append(len(text.split()))\n",
        "\n",
        "max_len = int(np.percentile(lengths, 95)) # Utilizando un largo que cubra al menos un 95% de las reviews.\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_vocab, oov_token=\"<OOV>\") # OOV: Out of vocabulary\n",
        "tokenizer.fit_on_texts(df_train['clean_review_text'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df_train['clean_review_text'])\n",
        "\n",
        "padded = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded, df_train['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear el modelo\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(input_dim=max_vocab, output_dim=100, input_length=max_len))\n",
        "model_rnn.add(SimpleRNN(64))\n",
        "model_rnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "\n",
        "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Ver el resumen del modelo\n",
        "\n",
        "model_rnn.summary()\n",
        "\n",
        "# Earlystopping para evitar overfitting\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model_rnn.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                        epochs=25, batch_size=128, callbacks=[early_stop],\n",
        "                        class_weight=class_weights_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76e2966",
      "metadata": {
        "id": "b76e2966"
      },
      "source": [
        "### Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "032a7ca2",
      "metadata": {
        "id": "032a7ca2"
      },
      "outputs": [],
      "source": [
        "# Obtener las probabilidades\n",
        "y_probs_rnn = model_rnn.predict(X_test)\n",
        "\n",
        "# Convertir probabilidades a clases binarias\n",
        "y_pred_rnn = (y_probs_rnn > 0.5).astype(int).flatten()\n",
        "\n",
        "# Mostrar el classification report\n",
        "report_rnn = classification_report(y_test, y_pred_rnn,target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print(\"\\n Reporte de Clasificación: RNN\")\n",
        "print(classification_report(y_test, y_pred_rnn,target_names=['Negativa', 'Positiva']))\n",
        "\n",
        "#  Evaluar el modelo\n",
        "loss, accuracy = model_rnn.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar accuracy vs val_accuracy\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "MxSnjfaKXnGl"
      },
      "id": "MxSnjfaKXnGl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener probabilidades de clase positiva\n",
        "y_probs = model_rnn.predict(X_test).ravel()  # .ravel() para convertir a vector 1D\n",
        "\n",
        "# Calcular curva ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "roc_auc_rnn = auc(fpr, tpr)\n",
        "print(f\"AUC: {roc_auc_rnn:.2f}\")\n",
        "\n",
        "# Graficar\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_rnn:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SOdvPsZ4nKIa"
      },
      "id": "SOdvPsZ4nKIa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegurarse de que las probabilidades estén en una dimensión compatible\n",
        "y_probs_rnn = y_probs_rnn.ravel()\n",
        "\n",
        "# Calcular precisión y recall\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_probs_rnn)\n",
        "avg_precision = average_precision_score(y_test, y_probs_rnn)\n",
        "\n",
        "# Graficar curva Precision-Recall\n",
        "print(f\"Average Precision (AP): {avg_precision:.2f}\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}', color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall - Modelo RNN')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pRTT909q23V1"
      },
      "id": "pRTT909q23V1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo completo\n",
        "model_rnn.save('/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/model_rnn.keras')"
      ],
      "metadata": {
        "id": "w-ibfg2IKQJm"
      },
      "id": "w-ibfg2IKQJm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b598dafa",
      "metadata": {
        "id": "b598dafa"
      },
      "source": [
        "## Análisis de sentimiento con BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f24dd85d",
      "metadata": {
        "id": "f24dd85d"
      },
      "source": [
        "### Importar los paquetes necesarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df79069e",
      "metadata": {
        "id": "df79069e"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer  # Para convertir oraciones en embeddings\n",
        "from sklearn.model_selection import train_test_split #split Train/Test\n",
        "from sklearn.linear_model import LogisticRegression # Regresión logística\n",
        "from sklearn.metrics import classification_report, confusion_matrix # Para evaluación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdde4aea",
      "metadata": {
        "id": "bdde4aea"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test Split\n",
        "\n",
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']"
      ],
      "metadata": {
        "id": "bzLHGRtydShB"
      },
      "id": "bzLHGRtydShB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58debb8",
      "metadata": {
        "id": "b58debb8"
      },
      "outputs": [],
      "source": [
        "# Generar los BERT Embeddings\n",
        "\n",
        "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
        "\n",
        "# Codificar X_train y X_test\n",
        "\n",
        "X_train_encoded = model.encode(df_train['clean_review_text'].astype(str).tolist(), show_progress_bar=True)\n",
        "\n",
        "X_test_encoded = model.encode(df_test['clean_review_text'].astype(str).tolist(), show_progress_bar=True)\n",
        "\n",
        "\n",
        "# Entrenar el classifier\n",
        "\n",
        "clf_bert = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "clf_bert.fit(X_train_encoded, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26e4d16a",
      "metadata": {
        "id": "26e4d16a"
      },
      "source": [
        "### Evaluar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3924566",
      "metadata": {
        "id": "b3924566"
      },
      "outputs": [],
      "source": [
        "y_pred = clf_bert.predict(X_test_encoded)\n",
        "\n",
        "# Matriz de confusion\n",
        "\n",
        "cm = confusion_matrix(y_test,\n",
        "                      y_pred)\n",
        "print(\"Matriz de confusión:\")\n",
        "print(cm)\n",
        "\n",
        "# Classification report\n",
        "\n",
        "report_bert = classification_report(y_test, y_pred,target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print('n\\Classification report: BERT')\n",
        "print(classification_report(y_test, y_pred,target_names=['Negativa', 'Positiva']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las probabilidades para cada clase\n",
        "y_probs = clf_bert.predict_proba(X_test_encoded)\n",
        "\n",
        "# Calcular ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, 1])  # Selecciona la clase positiva (segunda columna)\n",
        "roc_auc_bert = auc(fpr, tpr)\n",
        "\n",
        "# Mostrar el AUC\n",
        "print(f\"AUC: {roc_auc_bert:.2f}\")\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_bert:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fXuzVW2Cn4_x"
      },
      "id": "fXuzVW2Cn4_x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener probabilidades de clase positiva\n",
        "y_probs_bert = y_probs[:, 1]\n",
        "\n",
        "# Calcular precisión, recall y average precision\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_probs_bert)\n",
        "avg_precision = average_precision_score(y_test, y_probs_bert)\n",
        "\n",
        "# Graficar curva Precision-Recall\n",
        "print(f\"Average Precision (AP): {avg_precision:.2f}\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}', color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall - Modelo BERT')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TaEMY65_3PDV"
      },
      "id": "TaEMY65_3PDV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Guardar el clasificador\n",
        "joblib.dump(clf_bert, '/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/clf_bert.pkl')\n"
      ],
      "metadata": {
        "id": "cFXxval-Kbik"
      },
      "id": "cFXxval-Kbik",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9f488c75",
      "metadata": {
        "id": "9f488c75"
      },
      "source": [
        "## Análisis de sentimiento con Hugging Face Transformers (DistilBERT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af8039b7",
      "metadata": {
        "id": "af8039b7"
      },
      "source": [
        "### Importar los paquetes necesarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702340d6",
      "metadata": {
        "id": "702340d6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7a595a",
      "metadata": {
        "id": "ae7a595a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import (AutoTokenizer,TFAutoModelForSequenceClassification,\n",
        "                          DataCollatorWithPadding, create_optimizer)\n",
        "from datasets import Dataset\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "6uQhZBpGoBNi"
      },
      "id": "6uQhZBpGoBNi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d74bc88",
      "metadata": {
        "id": "2d74bc88"
      },
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']\n",
        "\n",
        "# Convertir el dataframe a un Hugging Face Dataset\n",
        "hf_train_dataset = Dataset.from_pandas(df_train[[\"clean_review_text\", \"target\"]])\n",
        "hf_test_dataset = Dataset.from_pandas(df_test[[\"clean_review_text\", \"target\"]])\n",
        "\n",
        "# Cargar el tokenizador y el modelo\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer_hft = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model_hft = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Tokenizar los datos\n",
        "def tokenize_function(example):\n",
        "    return tokenizer_hft(example[\"clean_review_text\"], truncation=True)\n",
        "\n",
        "tokenized_train_dataset = hf_train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test_dataset = hf_test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Preparar el data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_hft, return_tensors=\"tf\")\n",
        "\n",
        "# Convertir datasets a tf.data.Dataset\n",
        "tf_train_set = tokenized_train_dataset.to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"attention_mask\"],\n",
        "    label_cols=[\"target\"],\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_test_set = tokenized_test_dataset.to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"attention_mask\"],\n",
        "    label_cols=[\"target\"],\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "# Crear un EarlyStopping compatible con el modelo\n",
        "\n",
        "class SafeEarlyStopping(EarlyStopping):\n",
        "    def _implements_train_batch_hooks(self): return True\n",
        "    def _implements_test_batch_hooks(self): return True\n",
        "    def _implements_predict_batch_hooks(self): return True\n",
        "\n",
        "# Compilar y entrenar el modelo\n",
        "optimizer, schedule = create_optimizer(init_lr=5e-5, num_warmup_steps=0, num_train_steps=25627)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "model_hft.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "early_stop = SafeEarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model_hft.fit(\n",
        "    tf_train_set,\n",
        "    validation_data=tf_test_set,\n",
        "    epochs=10,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluar el modelo"
      ],
      "metadata": {
        "id": "anBWASJDn03g"
      },
      "id": "anBWASJDn03g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1125fd",
      "metadata": {
        "id": "cc1125fd"
      },
      "outputs": [],
      "source": [
        "# Visualizar accuracy vs val_accuracy\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el modelo entrenado de Hugging Face\n",
        "y_pred_probs = model_hft.predict(tf_test_set).logits\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Convertir etiquetas verdaderas del tf_dataset\n",
        "y_true = np.concatenate([y for x, y in tf_test_set], axis=0)\n",
        "\n",
        "\n",
        "# Reporte de clasificación\n",
        "report_hft = classification_report(y_true, y_pred, target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print(\"\\n Reporte de Clasificación: Hugging Face Transformers\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Negativa', 'Positiva']))\n"
      ],
      "metadata": {
        "id": "P-VoDSphcJrT"
      },
      "id": "P-VoDSphcJrT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular las probabilidades de la clase positiva\n",
        "y_pred_probs = tf.nn.softmax(y_pred_probs, axis=-1).numpy()[:, 1]  # Probabilidades de la clase positiva\n",
        "\n",
        "# Calcular ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
        "roc_auc_hft = auc(fpr, tpr)\n",
        "\n",
        "# Mostrar el AUC\n",
        "print(f\"AUC: {roc_auc_hft:.2f}\")\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_hft:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9kuyiftUIzLj"
      },
      "id": "9kuyiftUIzLj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular precisión, recall y average precision\n",
        "precision, recall, thresholds = precision_recall_curve(y_true, y_pred_probs)\n",
        "avg_precision = average_precision_score(y_true, y_pred_probs)\n",
        "\n",
        "# Graficar curva Precision-Recall\n",
        "print(f\"Average Precision (AP): {avg_precision:.2f}\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}', color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall - Modelo HFT')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A-pgE5HY3s9i"
      },
      "id": "A-pgE5HY3s9i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar modelo y tokenizador\n",
        "\n",
        "model_hft.save_pretrained('/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/hft_model')\n",
        "tokenizer_hft.save_pretrained('/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/hft_tokenizer')\n",
        "\n"
      ],
      "metadata": {
        "id": "q4k4LhewKmyi"
      },
      "id": "q4k4LhewKmyi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a65de29d",
      "metadata": {
        "id": "a65de29d"
      },
      "source": [
        "## Análisis de sentimiento con LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a611f0",
      "metadata": {
        "id": "53a611f0"
      },
      "source": [
        "### Importar paquetes necesarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "167a9f0f",
      "metadata": {
        "id": "167a9f0f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf #Importar Tensorflow\n",
        "from tensorflow.keras.models import Sequential #  Modelo secuencial\n",
        "from tensorflow.keras.layers import (Embedding, LSTM, Bidirectional, Dense,\n",
        "                                     Dropout, Conv1D, GlobalMaxPooling1D) # Layers requeridas\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Creación de tokens\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # Para evitar el overfitting\n",
        "from tensorflow.keras import regularizers # Para regularización\n",
        "import tensorflow.keras.backend as K # Para crear una métrica personalizada\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Normalización de texto\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Train/Test split\n",
        "from sklearn.preprocessing import LabelEncoder # Codificar etiquetas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "440b60ab",
      "metadata": {
        "id": "440b60ab"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40026a68",
      "metadata": {
        "id": "40026a68"
      },
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "\n",
        "X_train = df_train['clean_review_text']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['clean_review_text']\n",
        "y_test = df_test['target']\n",
        "\n",
        "\n",
        "# Crear tokens y ajustar las secuencias\n",
        "\n",
        "max_vocab = 10000 # Tamaño máximo de palabras a tomar en cuenta del texto\n",
        "\n",
        "lengths = []\n",
        "\n",
        "for index, text in df['clean_review_text'].items():\n",
        "    lengths.append(len(text.split()))\n",
        "\n",
        "max_len = int(np.percentile(lengths, 95)) # Utilizando un largo que cubra al menos un 95% de las reviews.\n",
        "\n",
        "tokenizer_lstm = Tokenizer(num_words=max_vocab, oov_token=\"<OOV>\") # OOV: Out of vocabulary\n",
        "tokenizer_lstm.fit_on_texts(df_train['clean_review_text'])\n",
        "\n",
        "sequences = tokenizer_lstm.texts_to_sequences(df_train['clean_review_text'])\n",
        "\n",
        "padded = pad_sequences(sequences,\n",
        "                       maxlen=max_len,\n",
        "                       padding='post',\n",
        "                       truncating='post')\n",
        "\n",
        "#  Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded,\n",
        "                                                    df_train['target'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Función F1 personalizada\n",
        "def f1_metric(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true * y_pred, 'float32'))\n",
        "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))\n",
        "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "\n",
        "# Tokenización\n",
        "max_vocab = 20000\n",
        "lengths = df['clean_review_text'].apply(lambda x: len(x.split()))\n",
        "max_len = int(np.percentile(lengths, 95))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_vocab, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df_train['clean_review_text'])\n",
        "\n",
        "X_sequences = tokenizer.texts_to_sequences(df_train['clean_review_text'])\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, df_train['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Modelo\n",
        "model_lstm = Sequential([\n",
        "    Embedding(max_vocab, 128, input_length=max_len),\n",
        "    Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_lstm.compile(loss='binary_crossentropy',\n",
        "                   optimizer='adam',\n",
        "                   metrics=['accuracy', f1_metric])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=1e-6)\n",
        "\n",
        "# Entrenamiento\n",
        "history_lstm = model_lstm.fit(X_train, y_train,\n",
        "                         validation_data=(X_test, y_test),\n",
        "                         epochs=12,\n",
        "                         batch_size=64,\n",
        "                         class_weight=class_weights_dict,\n",
        "                         callbacks=[early_stop, lr_reduce])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02cfa5d2",
      "metadata": {
        "id": "02cfa5d2"
      },
      "source": [
        "  ### Evaluar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ac4106",
      "metadata": {
        "id": "f7ac4106"
      },
      "outputs": [],
      "source": [
        "# Visualizar accuracy vs val_accuracy\n",
        "\n",
        "plt.plot(history_lstm.history['accuracy'], label='accuracy')\n",
        "plt.plot(history_lstm.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el modelo entrenado de LSTM\n",
        "\n",
        "y_pred_probs = model_lstm.predict(X_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "\n",
        "report_lstm = classification_report(y_test, y_pred, target_names=['Negativa', 'Positiva'],output_dict=True)\n",
        "print(\"\\Reporte de clasificación: LSTM\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negativa', 'Positiva']))"
      ],
      "metadata": {
        "id": "0engoCPxNsgH"
      },
      "id": "0engoCPxNsgH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular ROC y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "roc_auc_lstm = auc(fpr, tpr)\n",
        "\n",
        "# Mostrar AUC\n",
        "print(f\"AUC: {roc_auc_lstm:.2f}\")\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc_lstm:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UboTcmsUo4lM"
      },
      "id": "UboTcmsUo4lM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular precisión, recall y average precision\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
        "avg_precision = average_precision_score(y_test, y_pred_probs)\n",
        "\n",
        "# Graficar curva Precision-Recall\n",
        "print(f\"Average Precision (AP): {avg_precision:.2f}\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}', color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curva Precision-Recall - Modelo LSTM')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LDavN4u43-hV"
      },
      "id": "LDavN4u43-hV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo LSTM entrenado\n",
        "model_lstm.save('/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/lstm_model.keras')\n",
        "\n",
        "# Guardar el tokenizer\n",
        "tokenizer_path = '/content/drive/MyDrive/Capstone IMMUNE /Entregables/Modelos/tokenizer.json'\n",
        "tokenizer_json = tokenizer_lstm.to_json()\n",
        "\n",
        "# Guardar el tokenizer en un archivo JSON\n",
        "with open(tokenizer_path, 'w') as f:\n",
        "    f.write(tokenizer_json)"
      ],
      "metadata": {
        "id": "pgwytSWlLWUV"
      },
      "id": "pgwytSWlLWUV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección 4: Comparación entre modelos"
      ],
      "metadata": {
        "id": "1UUkGo5RZJNS"
      },
      "id": "1UUkGo5RZJNS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para extraer las metricas de los reportes\n",
        "\n",
        "# Función para extraer métricas\n",
        "def extract_metrics(report, model_name, roc_auc):\n",
        "    return {\n",
        "        \"Modelo\": model_name,\n",
        "        \"Precision Negativa\": report[\"Negativa\"][\"precision\"],\n",
        "        \"Recall Negativa\": report[\"Negativa\"][\"recall\"],\n",
        "        \"F1-score Negativa\": report[\"Negativa\"][\"f1-score\"],\n",
        "        \"Precision Positiva\": report[\"Positiva\"][\"precision\"],\n",
        "        \"Recall Positiva\": report[\"Positiva\"][\"recall\"],\n",
        "        \"F1-score Positiva\": report[\"Positiva\"][\"f1-score\"],\n",
        "        \"Precision (macro avg)\": report[\"macro avg\"][\"precision\"],\n",
        "        \"Recall (macro avg)\": report[\"macro avg\"][\"recall\"],\n",
        "        \"F1-score (macro avg)\": report[\"macro avg\"][\"f1-score\"],\n",
        "        \"Accuracy\": report[\"accuracy\"],\n",
        "        \"ROC AUC\": roc_auc\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ZYB3JxkgZK4w"
      },
      "id": "ZYB3JxkgZK4w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario de modelos\n",
        "report_dict = {\n",
        "    \"Regresión Logística\": report_rl,\n",
        "    \"SVM\": report_svm,\n",
        "    \"Naive Bayes\": report_nb,\n",
        "    \"Árbol de Decisión\": report_dt,\n",
        "    \"XGBoost\": report_xgb,\n",
        "    \"SVCLinear\": report_svcl,\n",
        "    \"Clasificador NLTK\": report_nltk,\n",
        "    \"RNN\": report_rnn,\n",
        "    \"BERT\": report_bert,\n",
        "    \"HuggingFace Transformers\": report_hft,\n",
        "    \"LSTM\": report_lstm,\n",
        "}\n",
        "\n",
        "roc_auc_dict = {\n",
        "    \"Regresión Logística\": roc_auc_rl,\n",
        "    \"SVM\": roc_auc_svm,\n",
        "    \"Naive Bayes\": roc_auc_nb,\n",
        "    \"Árbol de Decisión\": roc_auc_dt,\n",
        "    \"XGBoost\": roc_auc_xgb,\n",
        "    \"SVCLinear\": roc_auc_svcl,\n",
        "    \"Clasificador NLTK\": roc_auc_nltk,\n",
        "    \"RNN\": roc_auc_rnn,\n",
        "    \"BERT\": roc_auc_bert,\n",
        "    \"HuggingFace Transformers\": roc_auc_hft,\n",
        "    \"LSTM\": roc_auc_lstm,\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9JPsUDIsZfIK",
        "collapsed": true
      },
      "id": "9JPsUDIsZfIK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construcción del DataFrame comparativo\n",
        "comparative_results = []\n",
        "\n",
        "for model_name in report_dict:\n",
        "    report = report_dict[model_name]\n",
        "    roc_auc = roc_auc_dict[model_name]\n",
        "    comparative_results.append(extract_metrics(report, model_name, roc_auc))\n",
        "\n",
        "df_comparative = pd.DataFrame(comparative_results).set_index(\"Modelo\").round(3)\n",
        "\n",
        "# Mostrar tabla\n",
        "display(df_comparative.sort_values(by='ROC AUC',ascending=False))\n",
        "\n",
        "# Guardar la tabla\n",
        "\n",
        "df_comparative.to_csv('/content/drive/MyDrive/Capstone IMMUNE /Datasets/comparativa de modelos.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "34cXu00DE7C9"
      },
      "id": "34cXu00DE7C9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar por ROC AUC\n",
        "df_sorted = df_comparative.sort_values(by=\"ROC AUC\", ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df_sorted, x=df_sorted.index, y=\"ROC AUC\", palette=\"viridis\")\n",
        "plt.title(\"Comparación de ROC AUC por Modelo\", fontsize=14)\n",
        "plt.ylabel(\"ROC AUC\")\n",
        "plt.xlabel(\"Modelo\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lvhZlAK2fs6C"
      },
      "id": "lvhZlAK2fs6C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenamos las filas por alguna métrica relevante\n",
        "metric_sort = \"ROC AUC\"\n",
        "df_sorted = df_comparative.sort_values(by=metric_sort, ascending=False)\n",
        "\n",
        "# Configuración del mapa de calor\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.heatmap(\n",
        "    df_sorted,\n",
        "    annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5,\n",
        "    cbar_kws={'label': 'Valor de Métrica'}\n",
        ")\n",
        "\n",
        "plt.title(\"Métricas por Modelo\", fontsize=14, weight='bold')\n",
        "plt.xlabel(\"Métricas\")\n",
        "plt.ylabel(\"Modelo\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"heatmap_metricas_modelos.png\", dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dK7RHOEvh64n"
      },
      "id": "dK7RHOEvh64n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "5a8486d4",
        "mzQw-p0qQ8oy",
        "UXn_Uv2oXtGq"
      ],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}